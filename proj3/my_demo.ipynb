{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@Description :   \n",
    "@Author      :   Xubo Luo \n",
    "@Time        :   2024/01/08 16:04:58\n",
    "\"\"\"\n",
    "\n",
    "from core import *\n",
    "from torch_backend import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 网络&函数定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ColorMap()\n",
    "draw = lambda graph: display(DotGraph({p: ({'fillcolor': colors[type(v)], 'tooltip': repr(v)}, inputs) for p, (v, inputs) in graph.items() if v is not None}))\n",
    "\n",
    "\n",
    "batch_norm = partial(BatchNorm, weight_init=None, bias_init=None)\n",
    "\n",
    "def res_block(c_in, c_out, stride, **kw):\n",
    "    block = {\n",
    "        'bn1': batch_norm(c_in, **kw),\n",
    "        'relu1': nn.ReLU(True),\n",
    "        'branch': {\n",
    "            'conv1': nn.Conv2d(c_in, c_out, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            'bn2': batch_norm(c_out, **kw),\n",
    "            'relu2': nn.ReLU(True),\n",
    "            'conv2': nn.Conv2d(c_out, c_out, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "        }\n",
    "    }\n",
    "    projection = (stride != 1) or (c_in != c_out)    \n",
    "    if projection:\n",
    "        block['conv3'] = (nn.Conv2d(c_in, c_out, kernel_size=1, stride=stride, padding=0, bias=False), ['relu1'])\n",
    "    block['add'] =  (Add(), [('conv3' if projection else 'relu1'), 'branch/conv2'])\n",
    "    return block\n",
    "\n",
    "def DAWN_net(c=64, block=res_block, prep_bn_relu=False, concat_pool=True, **kw):    \n",
    "    if isinstance(c, int):\n",
    "        c = [c, 2*c, 4*c, 4*c]\n",
    "        \n",
    "    classifier_pool = {\n",
    "        'in': Identity(),\n",
    "        'maxpool': nn.MaxPool2d(4),\n",
    "        'avgpool': (nn.AvgPool2d(4), ['in']),\n",
    "        'concat': (Concat(), ['maxpool', 'avgpool']),\n",
    "    } if concat_pool else {'pool': nn.MaxPool2d(4)}\n",
    "    \n",
    "    return {\n",
    "        'input': (None, []),\n",
    "        'prep': union({'conv': nn.Conv2d(3, c[0], kernel_size=3, stride=1, padding=1, bias=False)},\n",
    "                      {'bn': batch_norm(c[0], **kw), 'relu': nn.ReLU(True)} if prep_bn_relu else {}),\n",
    "        'layer1': {\n",
    "            'block0': block(c[0], c[0], 1, **kw),\n",
    "            'block1': block(c[0], c[0], 1, **kw),\n",
    "        },\n",
    "        'layer2': {\n",
    "            'block0': block(c[0], c[1], 2, **kw),\n",
    "            'block1': block(c[1], c[1], 1, **kw),\n",
    "        },\n",
    "        'layer3': {\n",
    "            'block0': block(c[1], c[2], 2, **kw),\n",
    "            'block1': block(c[2], c[2], 1, **kw),\n",
    "        },\n",
    "        'layer4': {\n",
    "            'block0': block(c[2], c[3], 2, **kw),\n",
    "            'block1': block(c[3], c[3], 1, **kw),\n",
    "        },\n",
    "        'final': union(classifier_pool, {\n",
    "            'flatten': Flatten(),\n",
    "            'linear': nn.Linear(2*c[3] if concat_pool else c[3], 10, bias=True),\n",
    "        }),\n",
    "        'logits': Identity(),\n",
    "    }\n",
    "\n",
    "\n",
    "def conv_bn(c_in, c_out, bn_weight_init=1.0, **kw):\n",
    "    return {\n",
    "        'conv': nn.Conv2d(c_in, c_out, kernel_size=3, stride=1, padding=1, bias=False), \n",
    "        'bn': batch_norm(c_out, bn_weight_init=bn_weight_init, **kw), \n",
    "        'relu': nn.ReLU(True)\n",
    "    }\n",
    "\n",
    "def basic_net(channels, weight,  pool, **kw):\n",
    "    return {\n",
    "        'input': (None, []),\n",
    "        'prep': conv_bn(3, channels['prep'], **kw),\n",
    "        'layer1': dict(conv_bn(channels['prep'], channels['layer1'], **kw), pool=pool),\n",
    "        'layer2': dict(conv_bn(channels['layer1'], channels['layer2'], **kw), pool=pool),\n",
    "        'layer3': dict(conv_bn(channels['layer2'], channels['layer3'], **kw), pool=pool),\n",
    "        'pool': nn.MaxPool2d(4),\n",
    "        'flatten': Flatten(),\n",
    "        'linear': nn.Linear(channels['layer3'], 10, bias=False),\n",
    "        'logits': Mul(weight),\n",
    "    }\n",
    "\n",
    "def net(channels=None, weight=0.125, pool=nn.MaxPool2d(2), extra_layers=(), res_layers=('layer1', 'layer3'), **kw):\n",
    "    channels = channels or {'prep': 64, 'layer1': 128, 'layer2': 256, 'layer3': 512}\n",
    "    residual = lambda c, **kw: {'in': Identity(), 'res1': conv_bn(c, c, **kw), 'res2': conv_bn(c, c, **kw), \n",
    "                                'add': (Add(), ['in', 'res2/relu'])}\n",
    "    n = basic_net(channels, weight, pool, **kw)\n",
    "    for layer in res_layers:\n",
    "        n[layer]['residual'] = residual(channels[layer], **kw)\n",
    "    for layer in extra_layers:\n",
    "        n[layer]['extra'] = conv_bn(channels[layer], channels[layer], **kw)       \n",
    "    return n\n",
    "\n",
    "remove_identity_nodes = lambda net: remove_by_type(net, Identity)\n",
    "\n",
    "def train(model, lr_schedule, train_set, test_set, batch_size, num_workers=0):\n",
    "    train_batches = DataLoader(train_set, batch_size, shuffle=True, set_random_choices=True, num_workers=num_workers)\n",
    "    test_batches = DataLoader(test_set, batch_size, shuffle=False, num_workers=num_workers)\n",
    "    \n",
    "    lr = lambda step: lr_schedule(step/len(train_batches))/batch_size\n",
    "    opts = [SGD(trainable_params(model).values(), {'lr': lr, 'weight_decay': Const(5e-4*batch_size), 'momentum': Const(0.9)})]\n",
    "    logs, state = Table(), {MODEL: model, LOSS: x_ent_loss, OPTS: opts}\n",
    "    for epoch in range(lr_schedule.knots[-1]):\n",
    "        logs.append(union({'epoch': epoch+1, 'lr': lr_schedule(epoch+1)}, \n",
    "                          train_epoch(state, Timer(torch.cuda.synchronize), train_batches, test_batches)))\n",
    "    return logs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './data'\n",
    "dataset = cifar10(DATA_DIR)\n",
    "timer = Timer()\n",
    "print('Preprocessing training data')\n",
    "transforms = [\n",
    "    partial(normalise, mean=np.array(cifar10_mean, dtype=np.float32), std=np.array(cifar10_std, dtype=np.float32)),\n",
    "    partial(transpose, source='NHWC', target='NCHW'), \n",
    "]\n",
    "train_set = list(zip(*preprocess(dataset['train'], [partial(pad, border=4)] + transforms).values()))\n",
    "print(f'Finished in {timer():.2} seconds')\n",
    "print('Preprocessing test data')\n",
    "test_set = list(zip(*preprocess(dataset['valid'], transforms).values()))\n",
    "print(f'Finished in {timer():.2} seconds')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1x1conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortcut_block(c_in, c_out, stride, **kw):\n",
    "    projection = (stride != 1) or (c_in != c_out)\n",
    "    if projection:\n",
    "        return {\n",
    "            'conv':  nn.Conv2d(c_in, c_out, kernel_size=1, stride=stride, padding=0, bias=False), \n",
    "            'bn': batch_norm(c_out, **kw),\n",
    "            'relu': nn.ReLU(True),\n",
    "        }\n",
    "    else:\n",
    "        return {'id': Identity()}\n",
    "\n",
    "lr_schedule = PiecewiseLinear([0, 4, 20], [0, 0.4, 0])\n",
    "batch_size = 512\n",
    "\n",
    "n = DAWN_net(block=shortcut_block, prep_bn_relu=True)\n",
    "draw(build_graph(n))\n",
    "model = Network(n).to(device).half()\n",
    "train_set_x = Transform(train_set, [Crop(32, 32), FlipLR(), Cutout(8,8)])\n",
    "summary = train(model, lr_schedule, train_set_x, test_set, batch_size=batch_size, num_workers=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3x3conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortcut_block(c_in, c_out, stride, **kw):\n",
    "    projection = (stride != 1) or (c_in != c_out)\n",
    "    if projection:\n",
    "        return {\n",
    "            'conv': nn.Conv2d(c_in, c_out, kernel_size=3, stride=stride, padding=1, bias=False), \n",
    "            'bn': batch_norm(c_out, **kw),\n",
    "            'relu': nn.ReLU(True),\n",
    "        }\n",
    "    else:\n",
    "        return {'id': Identity()}\n",
    "\n",
    "lr_schedule = PiecewiseLinear([0, 4, 20], [0, 0.4, 0])\n",
    "batch_size = 512\n",
    "\n",
    "n = DAWN_net(block=shortcut_block, prep_bn_relu=True)\n",
    "draw(build_graph(n))\n",
    "model = Network(n).to(device).half()\n",
    "train_set_x = Transform(train_set, [Crop(32, 32), FlipLR(), Cutout(8,8)])\n",
    "summary = train(model, lr_schedule, train_set_x, test_set, batch_size=batch_size, num_workers=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortcut_block(c_in, c_out, stride, **kw):\n",
    "    projection = (stride != 1) or (c_in != c_out)\n",
    "    if projection:\n",
    "        return {\n",
    "            'conv': nn.Conv2d(c_in, c_out, kernel_size=3, stride=1, padding=1, bias=False), \n",
    "            'bn': batch_norm(c_out, **kw),\n",
    "            'relu': nn.ReLU(True),\n",
    "            'pool': nn.MaxPool2d(2),\n",
    "        }\n",
    "    else:\n",
    "        return {'id': Identity()}\n",
    "\n",
    "lr_schedule = PiecewiseLinear([0, 4, 20], [0, 0.4, 0])\n",
    "batch_size = 512\n",
    "\n",
    "n = DAWN_net(c=[64,128,256,512], block=shortcut_block, prep_bn_relu=True, concat_pool=False)\n",
    "draw(build_graph(n))\n",
    "model = Network(n).to(device).half()\n",
    "train_set_x = Transform(train_set, [Crop(32, 32), FlipLR(), Cutout(8,8)])\n",
    "summary = train(model, lr_schedule, train_set_x, test_set, batch_size=batch_size, num_workers=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## shortcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = PiecewiseLinear([0, 5, 24], [0, 0.4, 0])\n",
    "batch_size = 512\n",
    "\n",
    "n = net()\n",
    "draw(build_graph(n))\n",
    "model = Network(n).to(device).half()\n",
    "train_set_x = Transform(train_set, [Crop(32, 32), FlipLR(), Cutout(8,8)])\n",
    "summary = train(model, lr_schedule, train_set_x, test_set, batch_size=batch_size, num_workers=0)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
